{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32b8e4a",
   "metadata": {},
   "source": [
    "# Feature Vector MultiClass Classification\n",
    "\n",
    "This notebook contains the pipeline that allows to perform classification experiments of the Multi-Class version of this problem. **Cardboard**, **Metal**, **Paper**, **Glass**, and **Plastic** are the classes that are considered in this set of experiments. The used <u>data set</u> may be found in the following [Kaggle Repository](https://www.kaggle.com/asdasdasasdas/garbage-classification). \n",
    "\n",
    "clean_research_practice1_version.ipynb set the baseline in order to work with in this notebook, the binary classification version of the problem is worked in there. In case of doubts, this should be the reference to be consulted.\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3c07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from image_processing import applypca, applynmf\n",
    "from evaluation_functions import (hyperparametertunning, learningcurve, \n",
    "                                  plotlearningcurve, multiclass_CV)\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339be21",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7402cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/feature_extraction.csv', index_col=0)\n",
    "# df = pd.read_csv('data/fine_tuning.csv', index_col=0)\n",
    "\n",
    "X = df.iloc[:, 1:-5]\n",
    "y = df.iloc[:,-5:].to_numpy().argmax(axis=1)\n",
    "image_filenames = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd4559",
   "metadata": {},
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f28c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original BoF shape: (2390, 1280)\n",
      "BoF PCA shape: (2390, 1280)\n",
      "BoF PCA80 shape (2390, 168)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "X_pca, pca = applypca(X) \n",
    "\n",
    "variance = pca.explained_variance_ratio_\n",
    "\n",
    "suma = 0\n",
    "cont = 0\n",
    "while suma < 0.8:\n",
    "  suma += variance[cont]\n",
    "  cont += 1\n",
    "\n",
    "X_pca80 = X_pca.iloc[:,:cont]\n",
    "\n",
    "print(\"Original BoF shape:\",X.shape)\n",
    "print(\"BoF PCA shape:\",X_pca.shape)\n",
    "print(\"BoF PCA80 shape\",X_pca80.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf7f5e",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "## Experiment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54cd3990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exist\n",
      "Type Experiment Name: feature_extraction_XGBoost\n",
      "Type Model Name: XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Create Directory\n",
    "root = 'experiments/'\n",
    "# destination = '/content/drive/MyDrive/PI2/experiments'\n",
    "\n",
    "try:\n",
    "    os.mkdir(root)\n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print('Directory already exist')\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create Experiment Directory\n",
    "experiment = str(input('Type Experiment Name: '))\n",
    "path = root + experiment\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print('Directory already exist')\n",
    "    else:\n",
    "        raise\n",
    "model_name = str(input('Type Model Name: '))\n",
    "\n",
    "# Create training dictionary\n",
    "X_dict = {'Regular':X,'PCA':X_pca,'PCA80':X_pca80}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6a192",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Classifier - XGBoost\n",
    "model = xgb.XGBClassifier(objective='multi:softmax')\n",
    "hyperparameters = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}\n",
    "\n",
    "# Classifier - Random Forest\n",
    "# model = RandomForestClassifier(n_jobs=-1)\n",
    "# hyperparameters = {'n_estimators': [100, 250, 500],\n",
    "#                   'max_depth': [4, 8, 16, 32],\n",
    "#                   'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Classifier - Gaussian Naive Bayes\n",
    "# model = GaussianNB()\n",
    "# hyperparameters = {}\n",
    "\n",
    "# # Classifier - SVM\n",
    "# model = SVC(probability=True)\n",
    "\n",
    "# hyperparameters = {'C': [0.1, 1, 10, 100, 1000],\n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#               'kernel': ['rbf', 'sigmoid', 'linear']}\n",
    "\n",
    "# Classifier - Logistic\n",
    "# model = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "# hyperparameters = {'C': np.logspace(0,4,10), \n",
    "#                    'penalty': ['l1','l2','elasticnet','none']}\n",
    "\n",
    "# Tune Hyperparameters\n",
    "param_dict, param_title_dictionary = hyperparametertunning(model, X_dict, y, \n",
    "                                                           hyperparameters, 5, \n",
    "                                                           'f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ece89",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f372dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "(train_sizes_dict, train_scores_mean_dict, train_scores_std_dict,\n",
    "  test_scores_mean_dict, \n",
    "  test_scores_std_dict) = learningcurve(model, X_dict, y, \n",
    "                                        5, param_dict, 'f1_macro', \n",
    "                                        np.linspace(0.1,1,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlearningcurve(model_name, param_dict, param_title_dictionary, 'f1_macro', \n",
    "                  train_sizes_dict, train_scores_mean_dict, \n",
    "                  train_scores_std_dict, test_scores_mean_dict,\n",
    "                  test_scores_std_dict, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ce082",
   "metadata": {},
   "source": [
    "## Evaluating Performance Across Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f554d0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLASSES = ['cardboard', 'glass', 'metal', 'paper', 'plastic']\n",
    "df, model_wrong_preds = multiclass_CV(model, 5, X_dict, y, param_dict, \n",
    "                                      param_title_dictionary, CLASSES, \n",
    "                                      model_name, path, image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ea2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
